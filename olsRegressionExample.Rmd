---
title: "OLS Regression modeling in R"
author: Ben Anderson (b.anderson@soton.ac.uk, `@dataknut`)
date: 'Last run at: `r Sys.time()`'
output:
  html_document:
    keep_md: yes
    number_sections: yes
    self_contained: no
    toc: yes
    toc_depth: 4
    toc_float: yes
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    fig_caption: yes
    toc: yes
    toc_depth: 4
bibliography: ~/bibliography.bib
---
```{r knitrSetUp, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # echo code so reader can see what is happening
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig_caption = TRUE)
knitr::opts_chunk$set(fig_height = 6) # default, make it bigger to stretch vertical axis
knitr::opts_chunk$set(fig_width = 8) # full width
knitr::opts_chunk$set(tidy = TRUE) # tidy up code in case echo = TRUE
```

```{r codeSetup, include=FALSE}
# Housekeeping ----
rm(list=ls(all=TRUE)) # remove all objects from workspace

# Set start time ----
startTime <- Sys.time()
```

#Â Why are we here?

To learn how to do ols regression modelling in R (markdown) and specifically how to use broom [@broom] and car [@car] for diagnostics, stargazer [@stargazer] for model tables, data.table [@data.table] for data manipulation and ggplot [@ggplot2] for results visualisation. 

For more on regression try: http://socserv.socsci.mcmaster.ca/jfox/Courses/Brazil-2009/index.html 

So many birds and just one stone...

```{r set data}
# R has a very useful built-in dataset called mtcars
# http://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html

# A data frame with 32 observations on 11 variables.
# [, 1] 	mpg 	Miles/(US) gallon
# [, 2] 	cyl 	Number of cylinders
# [, 3] 	disp 	Displacement (cu.in.)
# [, 4] 	hp 	Gross horsepower
# [, 5] 	drat 	Rear axle ratio
# [, 6] 	wt 	Weight (1000 lbs)
# [, 7] 	qsec 	1/4 mile time
# [, 8] 	vs 	V/S
# [, 9] 	am 	Transmission (0 = automatic, 1 = manual)
# [,10] 	gear 	Number of forward gears
# [,11] 	carb 	Number of carburetors 

# Load required packages ----
x <- c("rms", #  regression tools
       "stargazer", # nice reporting of regressions
       "car", # regression tools
       "broom", # for tidying regression results
       "ggplot2", # for displaying regression results
       "data.table" # for fast data manipulation
       )
       
# do this to install them first if needed
#install.packages(x)
print("Loading required packages")

# be careful - this will return a FALSE if a package doesn't load but the script will NOT stop!
lapply(x, require, character.only = T)


# Load mtcars ----
mtcars <- mtcars

summary(mtcars) # base method
```

# Examine dataset

```{r examine data}
names(mtcars)
pairs(~mpg+disp+hp+drat+wt,labels=c(
  "Mpg","Displacement","Horse power", 
  "Rear axle rotation","Weight"), data=mtcars, main="Simple Scatterplot Matrix")
```

Establish normality of mpg (outcome variable of interest).

```{r normality}
hist(mtcars$mpg)
qqnorm(mtcars$mpg); qqline(mtcars$mpg, col = 2)

shapiro.test(mtcars$mpg)
# if p > 0.05 => normal 

# is it? Beware: shapiro-wilks is less robust as N -> 
```

# Model with 1 term predicting mpg

```{r model 1}
# qsec = time to go 1/4 mile from stationary
mpgModel1 <- lm(mpg ~ qsec, mtcars)

# results?
summary(mpgModel1)

# Diagnostics ----

plot(mpgModel1)

# normality of residuals
hist(mpgModel1$residuals)

qqnorm(mpgModel1$residuals); qqline(mpgModel1$residuals, col = 2)

shapiro.test(mpgModel1$residuals)

# it is usual to do these checks for standardised residuals - but the results are the same
# add casewise diagnostics back into dataframe
mtcars$studentised.residuals <- rstudent(mpgModel1)

qqnorm(mtcars$studentised.residuals); qqline(mtcars$studentised.residuals, col = 2)

shapiro.test(mtcars$studentised.residuals)

# if p > 0.05 => normal 
# is it?
# But don't rely on the test espcially with large n

# The 'car' package has some nice graphs to help here
qqPlot(mpgModel1) # shows default 95% CI
spreadLevelPlot(mpgModel1)
# Do we think the variance of the residuals is constant?
# Did the plot suggest a transformation? If so, why?

# autocorrelation/independence of errors
durbinWatsonTest(mpgModel1)
# if p < 0.05 then a problem as implies autocorrelation
# what should we conclude? Why? Could you have spotted that in the model summary?

# homoskedasticity
plot(mtcars$mpg,mpgModel1$residuals)
abline(h = mean(mpgModel1$residuals), col = "red") # add the mean of the residuals (yay, it's zero!)

# formal test
ncvTest(mpgModel1)
# if p > 0.05 then there is heteroskedasticity
# what do we conclude from the tests?
```

go back to the model - what can we conclude from it?

```{r report model 1}
summary(mpgModel1)
```

# Model with more than 1 term

So our model was mostly OK (one violated assumption?) but the r sq was quite low. 

Maybe we should add the car's weight?

```{r add wt}
# wt = weight of car
mpgModel2 <- lm(mpg ~ qsec + wt, mtcars)

# results?
summary(mpgModel2)

# Diagnostics ----
# we whould run the same checks e.g.:
qqPlot(mpgModel2) # shows default 95% CI
spreadLevelPlot(mpgModel2)

# but also
# additional assumption checks (now there are 2 predictors)

# collinearity
vif(mpgModel2)
# if any values > 10 -> problem

# tolerance
1/vif(mpgModel2)
# if any values < 0.2 -> possible problem
# if any values < 0.1 -> definitely a problem

# autocorrelation/independence of errors
durbinWatsonTest(mpgModel2)
# if p < 0.05 then a problem as implies autocorrelation

# comparing models
# as a reminder:
summary(mpgModel1)
summary(mpgModel2)

# test significant difference between models
anova(mpgModel1, mpgModel2)
# what should we conclude from that?
```

Whilst we're here we should also plot the residuals. h/t to https://gist.github.com/apreshill/9d33891b5f9be4669ada20f76f101baa for this.

```{r plot residuals}
# save the residuals via broom
resids <- augment(mpgModel2)

# plot fitted vs residuals
ggplot(resids, aes(x = .fitted, y = .resid)) + 
    geom_point(size = 1)
```

Hopefully we didn't see any obviously strange patterns (unlike that [gist](https://gist.github.com/apreshill/9d33891b5f9be4669ada20f76f101baa)).

# Reporting OLS results with confidence intervals

The p values tell you whether the 'effect' (co-efficient) is statistically significant. But only _you_ can decide if it is IMPORTANT!

It is usually better to calculate and inspect confidence intervals for your estimates.

This indicates:

 * statistical significance (if the CIs do not include 0) - just like the p value
 * precision - the width of the CIs shows you how precise your estimate is

You can calculate them using the standard error (s.e.) from the summary:

 * lower = estimate - (s.e.*1.96) 
 * upper = estimate + (s.e.*1.96)
 * just like for t tests etc (in fact this _is_ a t test!!)

Or use `confint()` which is more precise.

Print out the summaries again and calculate 95% confidence intervals each time.

```{r add CI to model 1}

# Model 1
# use confint to report confidence intervals with bonferroni corrected level
bc_p1 <- 0.05/length(mpgModel1$coefficients)

# save results as log odds
# the cbind function simply 'glues' the columns together side by side
mpgModel1Results_bf <- cbind(Coef = coef(mpgModel1), # coefficients
                              confint(mpgModel1, level = 1 - bc_p1), # 95% CI
                             Pr = round(summary(mpgModel1)$coefficients[,4], 3) # p value if required
                             )
mpgModel1Results_bf

# Model 2
# use confint to report confidence intervals with bonferroni corrected level
bc_p2 <- 0.05/length(mpgModel2$coefficients)

# save results as log odds
# the cbind function simply 'glues' the columns together side by side
mpgModel2Results_bf <- cbind(Coef = coef(mpgModel2),
                             confint(mpgModel2,level = 1 - bc_p2)
                             )

mpgModel2Results_bf
```

Now we'll try reporting the two model using the stargazer package to get pretty tables. Note we use options to automatically create the 95% CI and to report the results on just one line per predictor. This is especially helpful for models with a lot of variables.

```{r use stargazer, results='asis'}
stargazer(mpgModel1, mpgModel2, 
          title = "Model results",
          ci = TRUE, 
          single.row = TRUE,type = "html")
```

# Visualise results using ggplot

Now we'll visualise them using broom and ggplot. Just to confuse you we're going to convert the data frames to data.tables. It makes little difference here but data.table is good to get to know for `data science`.


```{r visualise models}
# Broom converts the model results into a data frame (very useful!)
mpgModel1DT <- as.data.table(tidy(mpgModel1))
mpgModel1DT$ci_lower <- mpgModel1DT$estimate - qnorm(0.975) * mpgModel1DT$std.error 
mpgModel1DT$ci_upper <- mpgModel1DT$estimate + qnorm(0.975) * mpgModel1DT$std.error
mpgModel1DT <- mpgModel1DT[, model := "Model 1"] # add model label for ggplot to pick up
mpgModel2DT <- as.data.table(tidy(mpgModel2))
mpgModel2DT$ci_lower <- mpgModel2DT$estimate - qnorm(0.975) * mpgModel2DT$std.error 
mpgModel2DT$ci_upper <- mpgModel2DT$estimate + qnorm(0.975) * mpgModel2DT$std.error
mpgModel2DT <- mpgModel2DT[, model := "Model 2"] # add model label for ggplot to pick up

modelsDT <- rbind(mpgModel1DT, mpgModel2DT)
  
ggplot(modelsDT, aes(x=term, y=estimate, fill = model)) + 
  geom_bar(position=position_dodge(), stat="identity") + 
  geom_errorbar(aes(ymin=ci_lower, 
                    ymax=ci_upper),
                    width=.2,
                    position=position_dodge(.9)
                    ) +
  labs(title = "Model results",
       x = 'Variable',
       y = 'Coefficient',
       caption = "Model results, 95% CI") +
  coord_flip() # rotate for legibility
                
```

# About

## Runtime

Analysis completed in: `r round(Sys.time() - startTime, 2)` seconds using [knitr](https://cran.r-project.org/package=knitr) in [RStudio](http://www.rstudio.com) with `r R.version.string` running on `r R.version$platform`.

R packages used:

 * base R - for the basics [@baseR]
 * ggplot2 - for slick graphics [@ggplot2]
 * car - for regression diagnostics [@car]
 * broom - for tidy model results [@broom]
 * data.table - for fast data manipulation [@data.table]
 * knitr - to create this document [@knitr]
                     
# References
